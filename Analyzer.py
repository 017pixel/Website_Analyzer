# MODELL_NAME = "gemini-2.5-flash-lite-preview-06-17" 

import whois
import socket
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import sys
import ssl
from urllib.parse import urlparse, urljoin
from datetime import datetime
from colorama import init, Fore, Style
import time

# Initialisiert Colorama fÃ¼r farbige Terminal-Ausgabe
init(autoreset=True)

def print_banner():
    banner = f"""
{Style.BRIGHT}{Fore.CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸŒ WEBSITE ANALYZER TOOL ğŸŒ                  â•‘
â•‘                      Professionelle Web-Analyse                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Style.RESET_ALL}
"""
    print(banner)

def print_header(title):
    """Druckt eine formatierte, farbige Ãœberschrift."""
    print(f"\n{Style.BRIGHT}{Fore.CYAN}â•­â”€â”€â”€ {title.upper()} â”€â”€â”€â•®{Style.RESET_ALL}")

def print_subheader(title):
    """Druckt eine formatierte UnterÃ¼berschrift."""
    print(f"\n{Style.BRIGHT}{Fore.YELLOW}â–¶ {title}{Style.RESET_ALL}")

def print_info(key, value):
    """Druckt ein SchlÃ¼ssel-Wert-Paar formatiert."""
    print(f"  {Fore.BLUE}â€¢ {key:<25}{Style.RESET_ALL}{Fore.WHITE}{value}{Style.RESET_ALL}")

def print_success(message):
    """Druckt eine Erfolgsmeldung."""
    print(f"  {Fore.GREEN}âœ“ {message}{Style.RESET_ALL}")

def print_warning(message):
    """Druckt eine Warnung."""
    print(f"  {Fore.YELLOW}âš  WARNUNG: {message}{Style.RESET_ALL}")

def print_error(message):
    """Druckt eine Fehlermeldung formatiert."""
    print(f"  {Fore.RED}âœ— FEHLER: {message}{Style.RESET_ALL}")

def print_separator():
    """Druckt eine dekorative Trennlinie."""
    print(f"{Fore.CYAN}{'â”€' * 70}{Style.RESET_ALL}")

def get_gemini_config():
    """Fragt nach Gemini API-SchlÃ¼ssel und konfiguriert das Modell."""
    print_header("KI-Analyse Konfiguration")
    
    while True:
        choice = input(f"{Style.BRIGHT}MÃ¶chten Sie die erweiterte KI-Analyse mit Google Gemini verwenden? (j/n): {Style.RESET_ALL}").strip().lower()
        
        if choice in ['j', 'ja', 'y', 'yes']:
            api_key = input(f"{Style.BRIGHT}Bitte geben Sie Ihren Google Gemini API-SchlÃ¼ssel ein: {Style.RESET_ALL}").strip()
            
            if not api_key:
                print_error("Kein API-SchlÃ¼ssel eingegeben!")
                continue
                
            try:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel("gemini-2.5-flash-lite-preview-06-17")
                
                # Test der API-Verbindung
                print(f"{Fore.YELLOW}Teste API-Verbindung...{Style.RESET_ALL}")
                test_response = model.generate_content("Hallo")
                print_success("Gemini API erfolgreich konfiguriert!")
                return model
                
            except Exception as e:
                print_error(f"API-Konfiguration fehlgeschlagen: {e}")
                retry = input(f"{Style.BRIGHT}MÃ¶chten Sie es erneut versuchen? (j/n): {Style.RESET_ALL}").strip().lower()
                if retry not in ['j', 'ja', 'y', 'yes']:
                    break
                continue
                
        elif choice in ['n', 'nein', 'no']:
            print_info("Modus:", "Analyse ohne KI-Funktionen")
            return None
            
        else:
            print_warning("Bitte geben Sie 'j' fÃ¼r Ja oder 'n' fÃ¼r Nein ein.")

def get_advanced_website_info(url, model=None):
    """
    Sammelt und analysiert umfassende Informationen Ã¼ber eine Website und prÃ¤sentiert sie strukturiert.
    """
    if not (url.startswith('http://') or url.startswith('https://')):
        url = 'https://' + url
    
    parsed_url = urlparse(url)
    domain = parsed_url.netloc
    base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"

    print_separator()
    print_header(f"Analyse fÃ¼r {domain}")
    print(f"  {Fore.CYAN}ğŸ” Ziel-URL: {Fore.WHITE}{url}{Style.RESET_ALL}")
    print_separator()

    # === 1. Domain- & Server-Informationen ===
    print_header("ğŸŒ Domain- & Server-Informationen")

    # --- WHOIS-Abruf ---
    print_subheader("ğŸ“‹ WHOIS-Registerdaten")
    try:
        w = whois.whois(domain)
        if w.creation_date:
            creation_date = w.creation_date[0] if isinstance(w.creation_date, list) else w.creation_date
            print_info("Erstellt am:", creation_date)
        if w.expiration_date:
            expiration_date = w.expiration_date[0] if isinstance(w.expiration_date, list) else w.expiration_date
            print_info("LÃ¤uft ab am:", expiration_date)
        if w.updated_date:
            updated_date = w.updated_date[0] if isinstance(w.updated_date, list) else w.updated_date
            print_info("Letztes Update:", updated_date)
        print_info("Registrar:", w.registrar or "Nicht verfÃ¼gbar")
        print_info("Organisation:", w.org or "Nicht verfÃ¼gbar")
        print_success("WHOIS-Daten erfolgreich abgerufen")
    except Exception as e:
        print_error(f"WHOIS-Abruf fehlgeschlagen: {e}")

    # --- DNS- & Netzwerk-Abruf ---
    print_subheader("ğŸŒ Netzwerkinformationen")
    try:
        ip_address = socket.gethostbyname(domain)
        print_info("IP-Adresse:", ip_address)
        print_success("Netzwerkinformationen abgerufen")
    except socket.gaierror:
        print_error("IP-Adresse konnte nicht ermittelt werden.")

    # --- SSL-Zertifikat ---
    print_subheader("ğŸ”’ SSL-Zertifikat")
    if parsed_url.scheme == 'https':
        try:
            context = ssl.create_default_context()
            with socket.create_connection((domain, 443), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=domain) as ssock:
                    cert = ssock.getpeercert()
                    subject = dict(x[0] for x in cert['subject'])
                    issuer = dict(x[0] for x in cert['issuer'])
                    
                    # Sicheres Datum-Parsing
                    try:
                        valid_from = datetime.strptime(cert['notBefore'], '%b %d %H:%M:%S %Y %Z')
                        valid_to = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
                        
                        print_info("Ausgestellt fÃ¼r:", subject.get('commonName', 'N/A'))
                        print_info("Aussteller:", issuer.get('organizationName', 'N/A'))
                        print_info("GÃ¼ltig von:", valid_from.strftime('%Y-%m-%d'))
                        print_info("GÃ¼ltig bis:", valid_to.strftime('%Y-%m-%d'))
                        
                        # PrÃ¼fe GÃ¼ltigkeit
                        now = datetime.now()
                        if now < valid_from or now > valid_to:
                            print_warning("Zertifikat ist abgelaufen oder noch nicht gÃ¼ltig!")
                        else:
                            print_success("SSL-Zertifikat ist gÃ¼ltig")
                    except ValueError as date_error:
                        print_error(f"Datum-Parsing fehlgeschlagen: {date_error}")
                        print_info("Zertifikat-Info:", "Grundlegende Informationen verfÃ¼gbar, Datum nicht lesbar")
                        
        except Exception as e:
            print_error(f"SSL-Zertifikat konnte nicht geprÃ¼ft werden: {e}")
    else:
        print_warning("Kein HTTPS, daher kein SSL-Zertifikat verfÃ¼gbar")

    # === 2. On-Page-Analyse ===
    print_header("ğŸ“„ On-Page-Analyse")
    text_content = ""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        print(f"  {Fore.YELLOW}ğŸ“¡ Lade Website-Inhalt...{Style.RESET_ALL}")
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()

        # --- Technische Details ---
        print_subheader("âš™ï¸ Technische Seitendetails")
        print_info("HTTP-Statuscode:", f"{response.status_code} âœ“" if response.status_code == 200 else f"{response.status_code} âš ")
        print_info("Server-Technologie:", response.headers.get('Server', 'Nicht erkannt'))
        print_info("Content-Type:", response.headers.get('Content-Type', 'Nicht erkannt'))
        print_info("Content-Length:", f"{len(response.content):,} Bytes" if response.content else "Nicht verfÃ¼gbar")
        
        if response.cookies:
            cookie_names = [cookie.name for cookie in response.cookies]
            print_info("Gesetzte Cookies:", f"{len(cookie_names)} Cookies: {', '.join(cookie_names[:3])}" + ("..." if len(cookie_names) > 3 else ""))
        else:
            print_info("Gesetzte Cookies:", "Keine")

        # --- Inhalts-Extraktion fÃ¼r KI ---
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Meta-Tags analysieren
        print_subheader("ğŸ·ï¸ Meta-Informationen")
        title = soup.find('title')
        print_info("Seitentitel:", title.text.strip() if title else "Nicht gefunden")
        
        description = soup.find('meta', attrs={'name': 'description'})
        print_info("Description:", description.get('content', 'Nicht gefunden') if description else "Nicht gefunden")
        
        keywords = soup.find('meta', attrs={'name': 'keywords'})
        print_info("Keywords:", keywords.get('content', 'Nicht gefunden') if keywords else "Nicht gefunden")
        
        # Text fÃ¼r KI extrahieren
        for element in soup(["script", "style", "nav", "footer", "aside", "header"]):
            element.decompose()
        text_content = soup.get_text(separator=' ', strip=True)
        
        max_chars = 45000
        if len(text_content) > max_chars:
            text_content = text_content[:max_chars]
            print_info("Extrahierter Text:", f"{len(text_content):,} Zeichen (gekÃ¼rzt fÃ¼r KI-Analyse)")
        else:
            print_info("Extrahierter Text:", f"{len(text_content):,} Zeichen")
        
        print_success("Website-Inhalt erfolgreich analysiert")

    except requests.RequestException as e:
        print_error(f"Website konnte nicht abgerufen werden: {e}")
        return

    # --- Robots.txt & Sitemap ---
    print_subheader("ğŸ¤– Crawler-Anweisungen")
    try:
        robots_url = urljoin(base_url, 'robots.txt')
        robots_res = requests.get(robots_url, headers=headers, timeout=8)
        if robots_res.status_code == 200:
            content_type = robots_res.headers.get('Content-Type', '').lower()
            # PrÃ¼fe ob es wirklich eine Text-Datei ist
            if 'text' in content_type or not content_type or 'robots' in robots_url:
                print_success("robots.txt gefunden und lesbar")
                robots_text = robots_res.text.lower()
                if "sitemap" in robots_text:
                    # Extrahiere Sitemap-URLs
                    sitemap_lines = [line.strip() for line in robots_res.text.split('\n') if 'sitemap:' in line.lower()]
                    if sitemap_lines:
                        print_success(f"Sitemap-Verweis gefunden: {len(sitemap_lines)} URL(s)")
                        for sitemap_line in sitemap_lines[:2]:  # Zeige max. 2 an
                            sitemap_url = sitemap_line.split(':', 1)[1].strip()
                            print_info("Sitemap:", sitemap_url)
                    else:
                        print_success("Sitemap-ErwÃ¤hnung in robots.txt gefunden")
                else:
                    print_info("Sitemap-Verweis:", "Keiner in robots.txt gefunden")
                
                # ZusÃ¤tzliche robots.txt Info
                if "user-agent:" in robots_text:
                    print_info("User-Agent Regeln:", "Vorhanden")
            else:
                print_warning("robots.txt gefunden, aber unerwarteter Content-Type")
        else:
            print_warning(f"robots.txt nicht verfÃ¼gbar (HTTP {robots_res.status_code})")
    except requests.RequestException as e:
        print_error(f"robots.txt konnte nicht geprÃ¼ft werden: {e}")

    # === 3. Erweiterte KI-Analyse mit Gemini ===
    if model and text_content:
        print_header("ğŸ¤– Gemini KI-Analyse")
        try:
            print(f"  {Fore.YELLOW}ğŸ§  KI analysiert Website-Inhalt...{Style.RESET_ALL}")
            
            # PrÃ¼fe TextlÃ¤nge fÃ¼r bessere API-Nutzung
            if len(text_content) < 100:
                print_warning("Sehr wenig Text gefunden - KI-Analyse kÃ¶nnte ungenau sein")
            
            prompt = f"""
            Analysiere den folgenden Text der Webseite '{domain}' umfassend.
            Gib die Antwort auf Deutsch und in einem klaren, strukturierten Format zurÃ¼ck.
            Verwende Emojis und eine ansprechende Formatierung fÃ¼r bessere Lesbarkeit.

            Beantworte die folgenden Punkte basierend auf dem Text:

            ğŸ¯ **ZUSAMMENFASSUNG**
            Fasse den Hauptzweck und Inhalt der Seite in 2-3 SÃ¤tzen zusammen.

            ğŸ‘¥ **ZIELGRUPPE**
            Wer ist die primÃ¤re Zielgruppe dieser Webseite? (z.B. Entwickler, Familien, Studenten, Unternehmen)

            ğŸ“ **TONALITÃ„T UND SPRACHE**
            Wie ist der Schreibstil? (z.B. formell, locker, technisch, werblich, informativ)

            ğŸ” **KERNTHEMEN & KEYWORDS**
            Liste die 5-7 wichtigsten Themen oder Keywords auf, die im Text vorkommen.

            ğŸ“¢ **CALL-TO-ACTIONS (CTAs)**
            Welche konkreten Handlungsaufforderungen werden an den Besucher gerichtet?

            ğŸ’° **GESCHÃ„FTSMODELL**
            Wie verdient diese Website wahrscheinlich Geld? (z.B. E-Commerce, Werbung, Abonnements)

            ğŸ† **BEWERTUNG**
            Bewerte die Website auf einer Skala von 1-10 bezÃ¼glich ProfessionalitÃ¤t und Benutzerfreundlichkeit.

            Hier ist der zu analysierende Text:
            ---
            {text_content}
            ---
            """
            
            # Gemini API Call mit Retry-Logic
            max_retries = 2
            for attempt in range(max_retries + 1):
                try:
                    gemini_response = model.generate_content(prompt)
                    if gemini_response.text:
                        print(f"\n{Style.BRIGHT}{Fore.GREEN}ğŸ‰ KI-Analyse abgeschlossen:{Style.RESET_ALL}")
                        print(f"{Fore.WHITE}{gemini_response.text}{Style.RESET_ALL}")
                        break
                    else:
                        print_warning("KI-Antwort war leer")
                        if attempt < max_retries:
                            print(f"  {Fore.YELLOW}Versuche erneut... ({attempt + 2}/{max_retries + 1}){Style.RESET_ALL}")
                            time.sleep(1)
                except Exception as api_error:
                    if attempt < max_retries:
                        print_warning(f"API-Versuch {attempt + 1} fehlgeschlagen, versuche erneut...")
                        time.sleep(2)
                    else:
                        raise api_error

        except Exception as e:
            print_error(f"Kommunikation mit der Gemini API fehlgeschlagen: {e}")
            if "quota" in str(e).lower():
                print_warning("MÃ¶glicherweise API-Quota erreicht. PrÃ¼fen Sie Ihr Gemini-Konto.")
    elif not model:
        print_header("â„¹ï¸  KI-Analyse Ã¼bersprungen")
        print_info("Status:", "KI-Analyse deaktiviert (kein API-SchlÃ¼ssel konfiguriert)")
    else:
        print_error("KI-Analyse nicht mÃ¶glich - kein Text von der Website extrahiert")

    print_separator()
    print(f"{Style.BRIGHT}{Fore.GREEN}âœ… Analyse fÃ¼r {domain} abgeschlossen!{Style.RESET_ALL}")
    print_separator()


def main():
    """Hauptfunktion des Website-Analyzer-Tools."""
    try:
        print_banner()
        
        # Gemini-Konfiguration
        model = get_gemini_config()
        
        print_separator()
        
        while True:
            website_url = input(f"{Style.BRIGHT}{Fore.CYAN}ğŸŒ Bitte geben Sie die URL der Website ein (z.B. wikipedia.org): {Style.RESET_ALL}").strip()
            
            if not website_url:
                print_warning("Keine URL eingegeben!")
                continue
                
            # BestÃ¤tigung anzeigen
            print(f"  {Fore.BLUE}â¤ Analysiere: {Fore.WHITE}{website_url}{Style.RESET_ALL}")
            
            # Analyse starten
            get_advanced_website_info(website_url, model)
            
            # Weitere Analyse anbieten
            while True:
                continue_choice = input(f"\n{Style.BRIGHT}MÃ¶chten Sie eine weitere Website analysieren? (j/n): {Style.RESET_ALL}").strip().lower()
                if continue_choice in ['j', 'ja', 'y', 'yes']:
                    break
                elif continue_choice in ['n', 'nein', 'no']:
                    print(f"\n{Style.BRIGHT}{Fore.CYAN}ğŸ‘‹ Vielen Dank fÃ¼r die Nutzung des Website Analyzer Tools!{Style.RESET_ALL}")
                    return
                else:
                    print_warning("Bitte geben Sie 'j' fÃ¼r Ja oder 'n' fÃ¼r Nein ein.")
                    
    except KeyboardInterrupt:
        print(f"\n{Style.BRIGHT}{Fore.YELLOW}âš  Programm vom Benutzer abgebrochen.{Style.RESET_ALL}")
    except Exception as e:
        print_error(f"Ein unerwarteter Fehler ist aufgetreten: {e}")


if __name__ == "__main__":
    main()
